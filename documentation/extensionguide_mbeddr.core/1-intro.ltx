
\vspace{50mm}


\begin{center} 
  \includegraphics{logoWithSlogan.png}

\vspace{5mm}
This document is part of the \\ 
mbeddr project at \ic{http://mbeddr.com}. 

\vspace{5mm}
This document is licensed under the \\ 
Eclipse Public License 1.0 (EPL).
\end{center}



\newpage


\setcounter{tocdepth}{2}
\tableofcontents
 
\newpage




\section{Introduction}

\subsection{Specific Challenges in Embedded Development}
\label{challenges}

This section provides an overview over some of the typical challenges
encountered in the development of embedded systems. We label these challenges
$C_1$ through $C_6$ so we can refer to the challenges from the later sections.

\paragraph{$C_1$: Abstraction without Runtime Cost} Abstractions that fit the
problem domain are important for modular and maintainable software. Functional
and object-oriented languages are a good first step in this direction, but
embedded software can make use of additional paradigms: state-based, reactive,
time-triggered and data flow are examples often used. Abstractions specific to
the application domain in which the embedded system will be used are also
common. In contrast to general purpose programming however, these abstractions
should come with minimal runtime cost, because the target environments for
embedded software are often severely resource constrained. This means that many
of the abstractions have to be resolved statically during translation, resulting
in an efficient C implementation. This constraint also rules out approaches
based on runtime reflection or runtime meta programming for building custom
abstractions.


\paragraph{$C_2$: Static Checks and Verification} To build safe, secure and
real-time systems, various forms of static analysis are used, from the
compiler's type checks to sophisticated model checking approaches. Detecting
problems at runtime is often too late --- the device may be deployed in a
non-accessible environment, or may have done harm to the real world already. As
a consequence of C's "permissive" type system and the fundamental challenge of
verifying turing-complete languages, verifying C programs is very expensive. To
make use of verification, those parts of a system that have to be verified
should be isolated from the rest, and expressed in a formalism that makes the
relevant verification feasible. An example formalism is state machines. However,
these parts of the system still have to be integrated with the rest of the
system, usually written in C. Extracting these parts into a completely separate
environment, such as a state chart modeling tool, results in integration
problems. 

Note how this requirements, together with the previous one, rules out the use of
libraries. Libraries don't provide static translation of abstractions,
validation and verification of the code as well as IDE support. Using the
preprocessor to create statically translated abstractionsis is also not a
utilizable option as this leads to brittle and unmaintainable code.

\paragraph{$C_3$: C considered Harmful} While being efficient and flexible,
especially for low-level, machine-dependent code, some of C's features are often
considered harmful. Unconstrained casting via \lcr{void} pointers, using
\lcr{int}s as Booleans or data structures like \lcr{union}s can result in
hard-to-detect runtime errors. Consequently, these features of C, as well as
others, are prohibited in many organizations. Standards such as MISRA-C limit
the language subset to what is considered \emph{safe}. However, most C IDEs are
not out of the box MISRA-C aware, so separate checkers have to be used and they
may or may not be integrated with developers' tools. This makes it hard for
developers to use the safe language subset of C efficiently.


\paragraph{$C_4$: Inclusion of Meta Data} Non-trivial embedded systems often
associate various kinds of meta data with program elements. Examples include
physical units, data encodings and value ranges for types, access restrictions,
memory mappings and access frequency restrictions for (global) variables as well
as trace information from code to other artifacts, typically requirements. These
meta data often form the basis for checking and analysis tools. Since C programs
cannot express these meta data directly (except as comments or \lcr{pragma}s,
with the obvious drawbacks), they are stored separately, often in XML files, and
related back to the program via qualified names. While there may be tool support
to check the consistency of these name references and to navigate between code
and meta data, scattering of the information leads to unnecessary complexity and
maintainability problems.

\paragraph{$C_5$: Tool Integration} The diverse requirements, as well as the
limitations of C discussed to far, often lead to the use of a wide variety of
tools used for a single embedded development project. While separate tools for
managing requirements or early design artefacts arguably make sense, this cannot
be said for many other concerns in the system. These include most of the meta
data discussed above as well as models expressed in alternative formalisms to
support abstraction and model checking. Most COTS tools are not open enough to
facilitate seamless and semantically meaningful integration with other tools
leading to significant accidental complexities.

\paragraph{$C_6$: Product Line Support} Most embedded systems are developed as
part of product lines. This leads to two problems. First, each product line, or
domain, comes with its own set of abstractions. If those can be made available
to the developer directly, writing code for that domain becomes much simpler,
and checks and verifications become more meaningful. We have already discuss
these limitations in building custom abstractions above. A second challenge is
the support for product line variability where certain (parts of) artifacts are
only included in some of the products in the product line. This variability
typically cross-cuts all the artifacts and tools, yet still has to be managed
efficiently. Today this variability on code level is often implemented with the
preprocessor leading to the problems discussed above and preventing static
analysis of variant consistency.


\section{Solution Approach}
\label{solapproach}

We address the challenges desribed above with an extensible version of the C
programming language. The following section briefly discusses language extension
in general and explores which kinds of extensions are necessary to address the
challenges $C_1$ to $C_6$. \sect{usingC} then shows how we address the
challenges with the extensible C.

\subsection{Language Extension}

In this chapter we distinguish various approaches of language modularization and
composition. Traditionally, languages have been combined by using an approach we
call \emph{referencing}. The partial programs written in different languages
reside in their own files and refer to each other with references, often using
qualified names. This approach is useful if the various partial programs
describe concerns of the system that should be separated. For example,
describing the deployment of components to hardware elements should be separated
from the definition of these components, because the two concerns are specified
at different times during system development, and the same set of components
should be deployable to \emph{different} hardware configurations without
changing the component definition. However, for many other extensions,
separation into files and cross-referencing does not work well. Syntactic
integration between the concerns in necessary. We identify two approaches that
provide syntactic integration: in language \emph{embedding} we compose
independent languages: the embedded language has no dependency on the language
it is embedded in. In language \emph{extension}, the extensions depend on the
extended language, for example, by inheriting from language concepts defined in
the base language. The extensible C language described in this paper mainly uses
language extension: the extended languages depend on C as the base language.


Language extension as we understand it provides deep syntactic and semantic
integration, as well as an IDE that is aware of the language extensions. It is
much more than a macro system or an open compiler. The language
extensions are not defined using meta programming (an approach where the base
language uses its own abstractions to define the extensions). Instead we use a
\emph{language workbench}, a tool that supports the flexible definition,
extension, composition and use of multiple languages. A language extension
defines new syntax, type system rules and semantics. Typically the semantics
of a language extension are defined by a transformation back to languages at a
lower abstraction level. For example, an extension that provides \emph{state
machines} is transformed back to a \lcr{switch/case}-based implementation in C.
At the end of this chain, the tree representing a pure C program is transformed
to text and submitted to existing C compilers. \fig{reduction} shows the
process.

\begin{figure}
\begin{center} 
  \includegraphics[width=12cm]{figures/reduction.png}
\end{center}
\vspace{-0.6cm}
\caption{Abstractions expressed in higher level languages (e.g. state machines
or components) are progressively reduced to their lower-level equivalent. At
the end, C text is generated that is subsequently compiled.}
\label{reduction}   
\end{figure} 

It is unlikely that a development organization is able to agree on 
\emph{one common} set of domain-specific extensions to C. Also, the resulting
language may become big and unwieldy. Thus, extensions have to be
\emph{modular}. They have to be created without modifying the original core
language, and unintended interactions between independently created extensions
must be taken care of. Users must be able to include only those language modules
they actually need.


\subsection{Ways to extend C}
\label{ways}

We argued above that to make language extension useful, the language syntax,
type system, semantics and IDE support need to be extensible. In this section we
discuss in which specific ways C needs to be extensible to make the overall
approach feasible.

\paragraph{$W_1$: Top Level Constructs} New top level constructs, on the level
of functions and \lcr{struct}s are necessary. Examples include test cases, state
machines, or interfaces and components. This enables the integration of new
programming paradigms relevant in particular domains.

\paragraph{$W_2$: Statements} New statements, such as an \lcr{assert} or
\lcr{fail} statement in test cases, should be supported. If statements introduce
new blocks, then variable visibility and shadowing must be handled correctly.
Statements (and other extensions) may have to be restricted to a specific
context; for example the the \lcr{assert} or \lcr{fail} statements must
\emph{only} be used in test cases.

\paragraph{$W_3$: Expressions} New expressions must be addable. An example is
the decision table expression that represents a two-level decision tree
(\fig{dectab}) as a two dimensional table. 

\begin{figure}
\rule{\textwidth}{0.7pt}
\vspace{-0.65cm}
\begin{center}  
  \includegraphics[width=9cm]{figures/dectabexample.jpg}
\end{center}
\vspace{-0.6cm}
\rule{\textwidth}{0.7pt}
\caption{A decision table expression. It evaluates to the value in the cell for
which the row and column header boolean expressions are true. If none is true,
the default value \lcr{-1} is applied.}
\label{dectab}  
\end{figure}

\paragraph{$W_4$: Types and Literals} New types, for example for matrices,
complex numbers or numbers with SI units must be addable. Adding new types also
requires defining new operators or overriding the typing rules for existing
operators. New literals may also be required to instantiate those types. For
example, a two-dimensional table notation could be used for instantiating
matrices (similar to the one in \fig{dectab}).

\paragraph{$W_5$: Transformation} Different transformations for existing
language concepts must be possible. For example, in a module marked as
\lcr{safe}, a \lcr{x + y} may have to be translated to calling
\lcr{addWithBoundsCheck(x, y)}. 


\paragraph{$W_6$: Meta Data Decoration} It should be possible to add meta data
such as trace links to requirements or product line variability specifications
to arbitrary any program elements.





